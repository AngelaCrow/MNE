library("rgdal")
library("raster")
library("fuzzySim")
library("ENMeval")
setwd("J:/USUARIOS/DarwinUICN/reuniones_talleres/taller lista roja/Resultados_TLR/Mapas_validos/MapasValidosPorGenero")
source("clean_dup.R")

set.seed(1)
#Ruta en la que se encuentra el poligono para hacer M de cada especie
shapePath <- "H:/CoberturasRestringidas/DarwinCLIMA"
shapeFile <- "wwf_eco_mesoa"
regionalizacion <- readOGR(shapePath, shapeFile)

#En esta primera parte se eliminan los registros en una celda de aproximadamene 1km2 (0.00833333333 arcos de seg)
setwd("J:/USUARIOS/DarwinUICN/reuniones_talleres/taller lista roja/Resultados_TLR/Mapas_validos/MapasValidosPorGenero/Capsicum")
dir.create("CleanUp_1km")

####LIMPIEZA DE DUPLICADOS####
sp_files <- list.files("FormatoIUCN",pattern = "*.csv$",full.names = TRUE)
x <- sp_files[[2]]
occs <- read.csv(x,header = T)
print(occs$Binomial[1])
clean_sp <- clean_dup(occs,"Dec_Long","Dec_Lat",threshold = 0.00833333333)
write.csv(clean_sp,file = paste0("CleanUp_1km/",clean_sp$Binomial[1],".csv"),row.names = FALSE)
rm(sp_files,occs)

#### Variables ambientales#### 
setwd("H:/CoberturasRestringidas/DarwinCLIMA")
clima<- stack(list.files("Clima",pattern="*.tif$",full.names = TRUE))


#### VARIABLES + PRESENCIAS#### 
setwd("J:/USUARIOS/DarwinUICN/reuniones_talleres/taller lista roja/Resultados_TLR/Mapas_validos/MapasValidosPorGenero/Capsicum/CleanUp_1km")
dir.create("extract")
  #sp_files <- list.files(pattern = "*.csv$",full.names = TRUE)
  coor<-c("Dec_Long","Dec_Lat")
  sp_coor<-clean_sp[coor]
  extract_cl <- extract(clima,sp_coor)
  extract_cl<-cbind(clean_sp,extract_cl)
  na_varname_index <- which(is.na(extract_cl$bio_1))
  if(length(na_varname_index)>0L) extract_cl <- extract_cl[-na_varname_index,]
  datos<-extract_cl
  
rm(na_varname_index, sp_coor)
####SELECCION DE VARIABLES####  
dir.create("variables")

  print(dim(datos))
  # analizar las correlaciones de dos en dos, y combinadas con la significacion sobre la especie:
  correlacion<-corSelect(data = datos, sp.cols = 3, var.cols = 23:ncol(datos), cor.thresh = 0.8, use = "pairwise.complete.obs")
  #Seleccionar solo las variables no correlacionadas del stack de las variables
  select_var<-as.data.frame(correlacion$selected.vars)
  vars <- levels(select_var$`correlacion$selected.vars`)
  write.csv(vars,file = paste0("variables/",datos$Binomial[1],"_var.csv"),row.names = FALSE)
  
  clima_sp=clima[[vars]] #Variables de la especie sin recortar
  rm(select_var, vars)
  
  # Seleccionar el 70 de los datos para calibrar y el resto para validar
  datos$cal_val <- NA
  ncalibracion <- floor(dim(datos)[1]*0.7)
  datos_cal <- sample(1:dim(datos)[1],size = ncalibracion)
  datos$cal_val[datos_cal] <- 1
  datos$cal_val[is.na(datos$cal_val)] <- 0
  
  ##Ahora cortar los raster con las ecoregiones donde exisan puntos de la especie
  coordinates(extract_cl) <- ~Dec_Long+Dec_Lat
  proj4string(extract_cl) <- proj4string(regionalizacion)
  
  #obtener los datos de los poligonos que tienen sitios de colecta
  dataenpoly<-over(extract_cl, regionalizacion, fn=NULL)
  enpolyindex<-which(!is.na(dataenpoly$ECO_NAME))
  polydatadf<-dataenpoly[enpolyindex,]
  id_polys<-unique(polydatadf$ECO_NAME)
  poligonofilter<-regionalizacion[regionalizacion$ECO_NAME %in% id_polys,]
  #recortamos el grid
  clima_cr<-crop(clima_sp,poligonofilter)
  env<-mask(clima_sp, poligonofilter) #M de la especie
  rm(clima_cr)
  
  #Proceso de modelacion, primero separar los datos de calibracion y validacion
  occs_train <- datos[datos$cal_val==1,]
  occs_train<-occs_train[,9:10]
  occs_train<-occs_train[c(2,1)]
  occs_test <- datos[datos$cal_val==0,]
  occs_test<-occs_test[,9:10]
  occs_test<-occs_test[c(2,1)]
#Bckground
 dir.create("outputs")
  bg <- randomPoints(env[[1]], n=10000)
  bg <- as.data.frame(bg)
  plot(env[[1]], legend=FALSE)
  points(bg, col='red')
  write.csv(bg,file = paste0("outputs/",datos$Binomial[1],"_bg.csv"),row.names = FALSE)
  
#Correr ENMeval
  sp <-ENMevaluate(occs_train, env, RMvalues = seq(0.5, 4, 0.5), 
                       fc = c("L", "LQ", "H", "LQH", "LQHP", "LQHPT"),
                       method = "randomkfold", kfolds = 4, bin.output = TRUE, 
                       parallel = TRUE, numCores = 8)

##elegir el modelo mÃ¡s parsimonioso
resultados_enmeval<-sp@results
write.csv(resultados_enmeval,file = paste0("outputs/",datos$Binomial[1],"_var.csv"),row.names = FALSE)
modelo<-sp@models[[which (sp@results$delta.AICc == 0) ]]
##tranferirlo a toda el area de estudio
PrediccionMx <- predict(modelo, clima_sp)
plot(PrediccionMx)

dir.create("modelos")
writeRaster(PrediccionMx,
            paste0("C:/CONABIO/",
                   datos$Binomial[1],".tif"),
            overwrite=TRUE)


##Validacion 
#maximizacion TSS y KAPPA

#Sensibilidad y especificidad
